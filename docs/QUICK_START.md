# Guide de d√©marrage rapide DispyCluster

Ce guide vous permet de mettre en place un cluster DispyCluster fonctionnel en moins de 30 minutes.

## üéØ Objectif

Cr√©er un cluster de Raspberry Pi capable de :
- Scraper des sites web de mani√®re distribu√©e
- Planifier des t√¢ches r√©currentes
- Monitorer les performances en temps r√©el
- G√©rer les workflows complexes

## üìã Pr√©requis

### Mat√©riel
- 1 Raspberry Pi ma√Ætre (Raspberry Pi 3B+ ou 4)
- 3+ Raspberry Pi workers (Raspberry Pi 3B+ ou 4)
- C√¢bles Ethernet ou WiFi
- Carte SD (16GB minimum) pour chaque Pi

### Logiciel
- Raspberry Pi OS Lite (recommand√©)
- Acc√®s SSH depuis le ma√Ætre vers chaque worker
- Docker et Docker Compose (sur le ma√Ætre)

## ‚ö° Installation en 5 √©tapes

### √âtape 1 : Pr√©parer l'inventaire (2 minutes)

√âditer le fichier `inventory/nodes.yaml` :

```yaml
# Exemple pour 3 workers
nodes:
  - host: node6.lan
    ip: 192.168.1.106
  - host: node7.lan  
    ip: 192.168.1.107
  - host: node8.lan
    ip: 192.168.1.108
```

### √âtape 2 : Installer les workers (5 minutes par worker)

Sur chaque Raspberry Pi worker :

```bash
# Copier le script d'installation
scp scripts/install_node.sh pi@node6.lan:~/
scp scripts/install_node.sh pi@node7.lan:~/
scp scripts/install_node.sh pi@node8.lan:~/

# Ex√©cuter sur chaque worker
ssh pi@node6.lan "sudo bash ~/install_node.sh"
ssh pi@node7.lan "sudo bash ~/install_node.sh"  
ssh pi@node8.lan "sudo bash ~/install_node.sh"
```

### √âtape 3 : Installer le ma√Ætre (5 minutes)

Sur le Raspberry Pi ma√Ætre :

```bash
# Installation du cluster de base
sudo bash scripts/install_master.sh

# Installation des services avanc√©s
sudo bash scripts/install_services.sh
```

### √âtape 4 : D√©marrer le monitoring (2 minutes)

```bash
# D√©marrer Prometheus et Grafana
cd monitoring
docker compose up -d

# V√©rifier que les conteneurs sont actifs
docker ps
```

### √âtape 5 : V√©rifier l'installation (3 minutes)

```bash
# Test complet des services
sudo bash scripts/test_services.sh

# V√©rification manuelle
curl http://localhost:8084/health
```

## üöÄ Premier test

### Test de scraping simple

```bash
# Scraping d'un site de test
curl -X POST http://localhost:8084/scrape \
  -H "Content-Type: application/json" \
  -d '{
    "start_url": "https://httpbin.org/html",
    "max_pages": 1,
    "timeout_s": 10
  }'
```

**R√©sultat attendu :**
```json
{
  "message": "Job cr√©√© avec succ√®s",
  "job_id": "job_1_1234567890",
  "status": "pending"
}
```

### Test de scraping en lot

```bash
# Scraping de plusieurs sites
curl -X POST http://localhost:8084/scrape/batch \
  -H "Content-Type: application/json" \
  -d '{
    "urls": [
      "https://httpbin.org/html",
      "https://httpbin.org/json",
      "https://httpbin.org/xml"
    ],
    "max_pages": 1,
    "priority": 2
  }'
```

### V√©rifier les r√©sultats

```bash
# Lister les jobs
curl http://localhost:8081/jobs

# Statistiques du cluster
curl http://localhost:8081/cluster

# Sant√© du cluster
curl http://localhost:8082/cluster/health
```

## üìä Acc√©der aux interfaces

### Tableaux de bord
- **API Gateway** : http://localhost:8084
- **Prometheus** : http://localhost:9090
- **Grafana** : http://localhost:3000 (admin/admin)

### Services individuels
- **Contr√¥leur** : http://localhost:8081
- **Monitoring** : http://localhost:8082
- **Planificateur** : http://localhost:8083

## üîß Configuration de base

### Variables d'environnement

```bash
# Ajouter au ~/.bashrc
export DISPYCLUSTER_ENV=development
export DISPYCLUSTER_LOG_LEVEL=INFO
```

### Configuration des services

√âditer `config/services_config.py` si n√©cessaire :

```python
# Ajuster les limites selon vos besoins
LIMITS = {
    "max_pages_per_job": 100,  # R√©duire pour les tests
    "max_urls_per_batch": 10,  # R√©duire pour les tests
    "max_timeout_seconds": 60  # Timeout plus court
}
```

## üìÖ Planifier une t√¢che

### T√¢che quotidienne

```bash
# Scraping quotidien √† 6h du matin
curl -X POST http://localhost:8083/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Scraping quotidien",
    "urls": ["https://news.com"],
    "max_pages": 10,
    "schedule_type": "cron",
    "schedule_config": {"cron": "0 6 * * *"},
    "priority": 3
  }'
```

### T√¢che r√©currente

```bash
# Toutes les 2 heures
curl -X POST http://localhost:8083/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Scraping r√©current",
    "urls": ["https://api.example.com/data"],
    "max_pages": 5,
    "schedule_type": "interval",
    "schedule_config": {"seconds": 7200},
    "priority": 2
  }'
```

## üîç Monitoring et surveillance

### V√©rifier la sant√© du cluster

```bash
# Vue d'ensemble
curl http://localhost:8084/overview

# D√©tails des workers
curl http://localhost:8082/nodes

# Performance
curl http://localhost:8082/performance?hours=1
```

### Surveiller les logs

```bash
# Logs en temps r√©el
journalctl -u dispycluster-controller -f
journalctl -u dispycluster-monitoring -f
journalctl -u dispycluster-scheduler -f
journalctl -u dispycluster-gateway -f
```

## üõ†Ô∏è Gestion des services

### Commandes utiles

```bash
# D√©marrer tous les services
sudo /opt/dispycluster/start_services.sh

# Arr√™ter tous les services
sudo /opt/dispycluster/stop_services.sh

# V√©rifier le statut
sudo /opt/dispycluster/check_services.sh

# Red√©marrer un service
sudo systemctl restart dispycluster-controller
```

### V√©rification du statut

```bash
# Statut des services
sudo systemctl status dispycluster-*

# Ports ouverts
sudo netstat -tlnp | grep -E "808[0-4]"

# Test de connectivit√©
curl http://localhost:8084/health
```

## üö® D√©pannage rapide

### Services non accessibles

```bash
# V√©rifier les services systemd
sudo systemctl status dispycluster-*

# Red√©marrer si n√©cessaire
sudo systemctl restart dispycluster-controller dispycluster-monitoring dispycluster-scheduler dispycluster-gateway
```

### Workers non d√©tect√©s

```bash
# Tester la connectivit√©
ping node6.lan
ping node7.lan
ping node8.lan

# Ping via l'API
curl -X POST http://localhost:8081/workers/node6.lan/ping
```

### Performance d√©grad√©e

```bash
# V√©rifier les m√©triques
curl http://localhost:8082/cluster/health

# Analyser les performances
curl http://localhost:8082/performance?hours=1

# V√©rifier les alertes
curl http://localhost:8082/alerts
```

## üìö Prochaines √©tapes

### Exploration avanc√©e

1. **Workflows complexes** : Cr√©er des workflows avec d√©pendances
2. **Monitoring personnalis√©** : Configurer des alertes sp√©cifiques
3. **Int√©gration** : Connecter avec vos applications existantes
4. **Optimisation** : Ajuster les param√®tres selon vos besoins

### Ressources utiles

- [Documentation compl√®te des services](SERVICES_README.md)
- [Architecture du syst√®me](ARCHITECTURE.md)
- [Exemples d'utilisation](../examples/cluster_usage_examples.py)
- [Configuration avanc√©e](../config/services_config.py)

## üéâ F√©licitations !

Votre cluster DispyCluster est maintenant op√©rationnel ! Vous pouvez :

- Scraper des sites web de mani√®re distribu√©e
- Planifier des t√¢ches r√©currentes
- Monitorer les performances en temps r√©el
- G√©rer des workflows complexes

Pour des fonctionnalit√©s avanc√©es, consultez la [documentation compl√®te](SERVICES_README.md).