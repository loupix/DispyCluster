# Guide de dÃ©pannage DispyCluster

Ce guide vous aide Ã  rÃ©soudre les problÃ¨mes courants avec votre cluster DispyCluster.

## ðŸ” Diagnostic rapide

### VÃ©rification de base

```bash
# Test complet des services
sudo bash scripts/test_services.sh

# VÃ©rification manuelle
curl http://localhost:8084/health
```

### Commandes de diagnostic

```bash
# Statut des services
sudo systemctl status dispycluster-*

# Ports ouverts
sudo netstat -tlnp | grep -E "808[0-4]"

# Logs rÃ©cents
journalctl -u dispycluster-controller --since "1 hour ago"
```

## ðŸš¨ ProblÃ¨mes courants

### 1. Services non accessibles

#### SymptÃ´mes
- Erreur "Connection refused" sur les ports 8080-8084
- Services systemd inactifs
- API Gateway non accessible

#### Solutions

**VÃ©rifier les services systemd :**
```bash
# Lister tous les services DispyCluster
sudo systemctl list-units --type=service | grep dispycluster

# RedÃ©marrer tous les services
sudo systemctl restart dispycluster-controller dispycluster-monitoring dispycluster-scheduler dispycluster-gateway

# VÃ©rifier le statut
sudo systemctl status dispycluster-*
```

**VÃ©rifier les ports :**
```bash
# VÃ©rifier que les ports sont ouverts
sudo netstat -tlnp | grep -E "808[0-4]"

# Tester la connectivitÃ©
curl -v http://localhost:8084/health
```

**VÃ©rifier les logs :**
```bash
# Logs du contrÃ´leur
journalctl -u dispycluster-controller -f

# Logs du monitoring
journalctl -u dispycluster-monitoring -f

# Logs du planificateur
journalctl -u dispycluster-scheduler -f

# Logs de l'API Gateway
journalctl -u dispycluster-gateway -f
```

#### Solutions avancÃ©es

**RÃ©installer les services :**
```bash
# ArrÃªter tous les services
sudo systemctl stop dispycluster-*

# RÃ©installer
sudo bash scripts/install_services.sh

# RedÃ©marrer
sudo systemctl start dispycluster-*
```

**VÃ©rifier les permissions :**
```bash
# VÃ©rifier les permissions des fichiers
ls -la /opt/dispycluster/services/

# Corriger si nÃ©cessaire
sudo chown -R pi:pi /opt/dispycluster/
sudo chmod +x /opt/dispycluster/services/*.py
```

### 2. Workers non dÃ©tectÃ©s

#### SymptÃ´mes
- Workers affichÃ©s comme "offline" dans l'API
- Erreurs de connexion aux workers
- Jobs non distribuÃ©s

#### Solutions

**VÃ©rifier la connectivitÃ© rÃ©seau :**
```bash
# Tester la connectivitÃ©
ping node6.lan
ping node7.lan
ping node8.lan

# Tester les ports spÃ©cifiques
telnet node6.lan 8080
telnet node6.lan 9100
```

**VÃ©rifier les services sur les workers :**
```bash
# VÃ©rifier le service de scraping
curl http://node6.lan:8080/health

# VÃ©rifier node_exporter
curl http://node6.lan:9100/metrics
```

**Ping via l'API :**
```bash
# Ping d'un worker spÃ©cifique
curl -X POST http://localhost:8081/workers/node6.lan/ping

# VÃ©rifier le statut
curl http://localhost:8081/workers
```

#### Solutions avancÃ©es

**RÃ©installer les workers :**
```bash
# Sur chaque worker
ssh pi@node6.lan "sudo systemctl restart dispynode"
ssh pi@node6.lan "sudo systemctl restart node_exporter"
```

**VÃ©rifier la configuration rÃ©seau :**
```bash
# VÃ©rifier les rÃ©solutions DNS
nslookup node6.lan
nslookup node7.lan
nslookup node8.lan

# VÃ©rifier les routes
ip route show
```

### 3. Performance dÃ©gradÃ©e

#### SymptÃ´mes
- Jobs qui prennent trop de temps
- Workers surchargÃ©s
- Erreurs de timeout

#### Solutions

**VÃ©rifier les mÃ©triques :**
```bash
# SantÃ© du cluster
curl http://localhost:8082/cluster/health

# Performance dÃ©taillÃ©e
curl http://localhost:8082/performance?hours=1

# MÃ©triques des nÅ“uds
curl http://localhost:8082/nodes
```

**Analyser les alertes :**
```bash
# Alertes actives
curl http://localhost:8082/alerts

# DÃ©tails d'un nÅ“ud
curl http://localhost:8082/nodes/node6.lan
```

**Optimiser la configuration :**
```bash
# Ã‰diter la configuration
nano config/services_config.py

# Ajuster les limites
LIMITS = {
    "max_pages_per_job": 50,  # RÃ©duire si nÃ©cessaire
    "max_timeout_seconds": 60,  # Timeout plus court
    "max_priority": 5  # Limiter les prioritÃ©s
}
```

#### Solutions avancÃ©es

**Redistribuer les charges :**
```bash
# ArrÃªter les jobs en cours
curl http://localhost:8081/jobs | jq '.[] | select(.status == "running") | .id' | xargs -I {} curl -X POST http://localhost:8081/jobs/{}/cancel

# RedÃ©marrer les services
sudo systemctl restart dispycluster-controller
```

**VÃ©rifier les ressources :**
```bash
# Utilisation CPU
top -p $(pgrep -f dispycluster)

# Utilisation mÃ©moire
free -h

# Utilisation disque
df -h
```

### 4. Erreurs de scraping

#### SymptÃ´mes
- Jobs qui Ã©chouent
- Erreurs de timeout
- Sites inaccessibles

#### Solutions

**VÃ©rifier les logs des jobs :**
```bash
# Lister les jobs rÃ©cents
curl http://localhost:8081/jobs | jq '.[] | select(.status == "failed")'

# DÃ©tails d'un job spÃ©cifique
curl http://localhost:8081/jobs/job_123
```

**Tester manuellement :**
```bash
# Test simple
curl -X POST http://localhost:8084/scrape \
  -H "Content-Type: application/json" \
  -d '{"start_url": "https://httpbin.org/html", "max_pages": 1}'
```

**Ajuster les paramÃ¨tres :**
```bash
# Timeout plus long
curl -X POST http://localhost:8084/scrape \
  -H "Content-Type: application/json" \
  -d '{
    "start_url": "https://example.com",
    "max_pages": 5,
    "timeout_s": 60,
    "priority": 1
  }'
```

#### Solutions avancÃ©es

**VÃ©rifier la connectivitÃ© internet :**
```bash
# Test de connectivitÃ©
curl -I https://httpbin.org/html
curl -I https://example.com
```

**Ajuster la configuration de scraping :**
```python
# Dans config/services_config.py
SCRAPING_CONFIG = {
    "default_user_agent": "DispyCluster/1.0",
    "delay_between_requests": 2,  # DÃ©lai plus long
    "max_redirects": 10,  # Plus de redirections
    "timeout": 30  # Timeout plus long
}
```

### 5. ProblÃ¨mes de planification

#### SymptÃ´mes
- TÃ¢ches planifiÃ©es non exÃ©cutÃ©es
- Workflows qui Ã©chouent
- Scheduler non accessible

#### Solutions

**VÃ©rifier le scheduler :**
```bash
# Statut du scheduler
curl http://localhost:8083/health

# TÃ¢ches planifiÃ©es
curl http://localhost:8083/tasks

# Planning
curl http://localhost:8083/schedule
```

**VÃ©rifier les logs :**
```bash
# Logs du scheduler
journalctl -u dispycluster-scheduler -f
```

**Tester une tÃ¢che simple :**
```bash
# CrÃ©er une tÃ¢che de test
curl -X POST http://localhost:8083/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Test",
    "urls": ["https://httpbin.org/html"],
    "max_pages": 1,
    "schedule_type": "once",
    "schedule_config": {}
  }'
```

#### Solutions avancÃ©es

**RedÃ©marrer le scheduler :**
```bash
sudo systemctl restart dispycluster-scheduler
```

**VÃ©rifier la configuration :**
```bash
# VÃ©rifier la configuration du scheduler
cat /opt/dispycluster/services/scheduler_service.py | grep -A 10 "SCHEDULER_CONFIG"
```

## ðŸ”§ Outils de diagnostic

### Scripts de diagnostic

```bash
# Test complet
sudo bash scripts/test_services.sh

# VÃ©rification des services
sudo /opt/dispycluster/check_services.sh

# Test de connectivitÃ©
ping -c 3 node6.lan
ping -c 3 node7.lan
ping -c 3 node8.lan
```

### Commandes de monitoring

```bash
# Surveillance en temps rÃ©el
watch -n 5 'curl -s http://localhost:8084/health | jq'

# MÃ©triques des nÅ“uds
watch -n 10 'curl -s http://localhost:8082/nodes | jq'

# Jobs en cours
watch -n 5 'curl -s http://localhost:8081/jobs | jq ".[] | select(.status == \"running\")"'
```

### Logs utiles

```bash
# Logs systÃ¨me
journalctl -u dispycluster-* --since "1 hour ago"

# Logs Docker (monitoring)
docker logs monitoring-prometheus-1
docker logs monitoring-grafana-1

# Logs Dispy
journalctl -u dispyscheduler -f
journalctl -u dispynode -f
```

## ðŸš¨ ProblÃ¨mes critiques

### Cluster complÃ¨tement hors ligne

**Diagnostic :**
```bash
# VÃ©rifier tous les services
sudo systemctl status dispycluster-* dispyscheduler

# VÃ©rifier les ports
sudo netstat -tlnp | grep -E "808[0-4]|51347"

# VÃ©rifier les logs
journalctl -u dispycluster-* --since "1 hour ago"
```

**Solution :**
```bash
# RedÃ©marrer tous les services
sudo systemctl restart dispycluster-* dispyscheduler

# VÃ©rifier le statut
sudo systemctl status dispycluster-* dispyscheduler
```

### Workers complÃ¨tement inaccessibles

**Diagnostic :**
```bash
# Tester la connectivitÃ©
ping node6.lan
ping node7.lan
ping node8.lan

# VÃ©rifier les services sur les workers
ssh pi@node6.lan "sudo systemctl status dispynode node_exporter"
```

**Solution :**
```bash
# RedÃ©marrer les services sur les workers
ssh pi@node6.lan "sudo systemctl restart dispynode node_exporter"
ssh pi@node7.lan "sudo systemctl restart dispynode node_exporter"
ssh pi@node8.lan "sudo systemctl restart dispynode node_exporter"
```

### Monitoring non accessible

**Diagnostic :**
```bash
# VÃ©rifier Docker
docker ps

# VÃ©rifier les conteneurs
docker logs monitoring-prometheus-1
docker logs monitoring-grafana-1
```

**Solution :**
```bash
# RedÃ©marrer le monitoring
cd monitoring
docker compose down
docker compose up -d
```

## ðŸ“ž Support et ressources

### Logs Ã  collecter

En cas de problÃ¨me persistant, collectez ces informations :

```bash
# CrÃ©er un rapport de diagnostic
mkdir -p /tmp/dispycluster-debug
cd /tmp/dispycluster-debug

# Statut des services
sudo systemctl status dispycluster-* > services-status.txt

# Logs rÃ©cents
journalctl -u dispycluster-* --since "1 hour ago" > services-logs.txt

# Configuration rÃ©seau
ip addr show > network-config.txt
ip route show > network-routes.txt

# Ports ouverts
sudo netstat -tlnp > open-ports.txt

# Test de connectivitÃ©
curl -s http://localhost:8084/health > api-health.json
curl -s http://localhost:8081/cluster > cluster-stats.json
curl -s http://localhost:8082/cluster/health > cluster-health.json

# CrÃ©er une archive
tar -czf dispycluster-debug-$(date +%Y%m%d-%H%M%S).tar.gz *.txt *.json
```

### Ressources utiles

- [Documentation complÃ¨te des services](SERVICES_README.md)
- [Guide de dÃ©marrage rapide](QUICK_START.md)
- [Architecture du systÃ¨me](ARCHITECTURE.md)
- [Exemples d'utilisation](../examples/cluster_usage_examples.py)

### Commandes de rÃ©cupÃ©ration

```bash
# RÃ©installation complÃ¨te des services
sudo bash scripts/install_services.sh

# RedÃ©marrage complet du cluster
sudo systemctl restart dispycluster-* dispyscheduler
sudo systemctl restart dispynode  # Sur chaque worker

# RedÃ©marrage du monitoring
cd monitoring
docker compose restart
```

## ðŸŽ¯ PrÃ©vention des problÃ¨mes

### Maintenance rÃ©guliÃ¨re

```bash
# VÃ©rification hebdomadaire
sudo bash scripts/test_services.sh

# Nettoyage des logs
sudo journalctl --vacuum-time=7d

# VÃ©rification de l'espace disque
df -h
```

### Surveillance proactive

```bash
# Script de surveillance
#!/bin/bash
while true; do
    if ! curl -s http://localhost:8084/health > /dev/null; then
        echo "ALERTE: API Gateway non accessible"
        # Envoyer une notification
    fi
    sleep 60
done
```

### Sauvegarde de la configuration

```bash
# Sauvegarder la configuration
tar -czf dispycluster-config-$(date +%Y%m%d).tar.gz \
    config/ \
    inventory/ \
    /etc/systemd/system/dispycluster-*.service
```